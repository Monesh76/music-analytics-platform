# Real-Time Music Data Aggregation Pipeline Configuration
# Copy this file to .env and fill in your values

# === REQUIRED SETTINGS ===

# Google Cloud Project ID
GOOGLE_CLOUD_PROJECT=your-project-id

# Claude API Key from Anthropic
CLAUDE_API_KEY=your-claude-api-key-here

# BigQuery Dataset Name
BIGQUERY_DATASET=music_analytics

# === OPTIONAL SETTINGS ===

# Environment (dev, staging, prod)
ENVIRONMENT=dev

# Google Cloud Region
DATAFLOW_REGION=us-central1
DATAFLOW_ZONE=us-central1-a

# Pub/Sub Topics
RAW_EVENTS_TOPIC=raw-music-events
ENRICHMENT_TOPIC=music-events-enrichment
ENRICHED_EVENTS_TOPIC=enriched-music-events

# BigQuery Tables
RAW_EVENTS_TABLE=raw_music_events
ENRICHED_EVENTS_TABLE=enriched_music_events

# Cloud Storage Bucket (auto-generated if not specified)
STORAGE_BUCKET=

# Dataflow Locations (auto-generated if not specified)
DATAFLOW_TEMP_LOCATION=
DATAFLOW_STAGING_LOCATION=

# === PROCESSING SETTINGS ===

# Batch processing size
BATCH_SIZE=100

# Maximum number of workers
MAX_WORKERS=4

# === MONITORING SETTINGS ===

# Enable monitoring and logging
ENABLE_MONITORING=true

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# === DEVELOPMENT SETTINGS ===

# Enable debug mode for local development
DEBUG=false

# Local testing mode (uses DirectRunner instead of DataflowRunner)
LOCAL_MODE=false 